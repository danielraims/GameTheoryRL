{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpqgXOv498Cu"
      },
      "source": [
        "# **LINEAR PROGRAMMING AND ZERO SUM GAMES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8SfoB-Fjd0M",
        "outputId": "12b58d5e-1fb7-461b-bad6-0a8d8a498e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nashpy\n",
            "  Downloading nashpy-0.0.40-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from nashpy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from nashpy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nashpy) (3.2.1)\n",
            "Collecting deprecated>=1.2.14 (from nashpy)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.14->nashpy) (1.14.1)\n",
            "Installing collected packages: deprecated, nashpy\n",
            "Successfully installed deprecated-1.2.14 nashpy-0.0.40\n"
          ]
        }
      ],
      "source": [
        "!pip install nashpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf0YLyVCroiF"
      },
      "source": [
        "**Re-formulation-of-the-linear-program**\n",
        "\n",
        "In a zero game, given a row player payoff matrix \\(A\\) with \\(m\\) rows and \\(n\\) columns, the following linear program will give the max-min strategy and value:\n",
        "\n",
        "$$\\min\\limits_{x \\in \\mathbb{R}^{(m + 1) \\times 1}}cx$$\n",
        "\n",
        "Subject to:\n",
        "\n",
        "\\begin{array}{r}\n",
        "\\begin{matrix}\n",
        "{M_{\\text{ub}}x} & {\\leq b_{\\text{ub}}} & & \\\\\n",
        "{M_{\\text{eq}}x} & {= b_{\\text{eq}}} & & \\\\\n",
        "x_{i} & {\\geq 0} & & {\\text{~for~}i \\leq m} \\\\\n",
        "\\end{matrix} \\\\\n",
        "\\end{array}\n",
        "\n",
        "Where the coefficients of the linear program are defined by:\n",
        "\n",
        "\\begin{array}{r}\n",
        "\\begin{matrix}\n",
        "c & {= (\\underset{m}{\\underbrace{0,\\ldots,0}}, - 1)} & & {c \\in \\{ 0,1\\}^{1 \\times (m + 1)}} \\\\\n",
        "M_{\\text{ub}} & {= \\begin{pmatrix}\n",
        "{( - A^{T})_{11}} & \\ldots & {( - A^{T})_{1m}} & 1 \\\\\n",
        " \\vdots & \\ddots & \\vdots & 1 \\\\\n",
        "{( - A^{T})_{n1}} & \\ldots & {( - A^{T})_{nm}} & 1 \\\\\n",
        "\\end{pmatrix}} & & {M \\in \\mathbb{R}^{n \\times (m + 1)}} \\\\\n",
        "b_{\\text{ub}} & {= (\\underset{n}{\\underbrace{0,\\ldots,0}})^{T}} & & {b_{\\text{ub}} \\in \\{ 0\\}^{n \\times 1}} \\\\\n",
        "M_{\\text{eq}} & {= (\\underset{m}{\\underbrace{1,\\ldots,1}},0)} & & {M_{\\text{eq}} \\in \\{ 0,1\\}^{1 \\times (m + 1)}} \\\\\n",
        "b_{\\text{eq}} & {= 1} & & \\\\\n",
        "\\end{matrix} \\\\\n",
        "\\end{array}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oggnHOC-t90N",
        "outputId": "eb46d245-f45e-4048-a8e0-596f2e424ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max-Min Strategy (Row Player): [0.5 0.5]\n",
            "Min-Max Strategy (Column Player): [0.5 0.5]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "import nashpy as nash\n",
        "np.set_printoptions(precision = 2)\n",
        "def find_max_min_strategies(payoff_matrix):\n",
        "    m, n = payoff_matrix.shape\n",
        "\n",
        "    ### Max-min strategy for the row player\n",
        "    c_row = np.concatenate([np.zeros(m), [-1]])\n",
        "    M_ub_row = np.concatenate([np.transpose(-payoff_matrix), np.ones((n, 1))], axis=1)\n",
        "    b_ub_row = np.zeros(n)\n",
        "    M_eq_row = np.concatenate([np.ones(m), [0]])\n",
        "    b_eq_row = 1\n",
        "    bounds_row = [(0, None)] * m + [(None, None)]\n",
        "    result_row = linprog(c_row, A_ub=M_ub_row, b_ub=b_ub_row, A_eq=[M_eq_row], b_eq=[b_eq_row], bounds=bounds_row, method='highs')\n",
        "    max_min_strategy_row = result_row.x[:-1]\n",
        "    max_min_value_row = -result_row.fun\n",
        "\n",
        "    ### Min-max strategy for the column player\n",
        "    c_col = np.concatenate([np.zeros(n), [1]])\n",
        "    M_ub_col = np.concatenate([payoff_matrix, -np.ones((m, 1))], axis=1)\n",
        "    b_ub_col = np.zeros(m)\n",
        "    M_eq_col = np.concatenate([np.ones(n), [0]])\n",
        "    b_eq_col = 1\n",
        "    bounds_col = [(0, None)] * n + [(None, None)]\n",
        "    result_col = linprog(c_col, A_ub=M_ub_col, b_ub=b_ub_col, A_eq=[M_eq_col], b_eq=[b_eq_col], bounds=bounds_col, method='highs')\n",
        "    min_max_strategy_col = result_col.x[:-1]\n",
        "    min_max_value_col = result_col.fun\n",
        "\n",
        "    return max_min_strategy_row, max_min_value_row, min_max_strategy_col, min_max_value_col\n",
        "\n",
        "matching_pennies = np.array([\n",
        "    [1,-1],\n",
        "    [-1,1]\n",
        "])\n",
        "max_min_strategy_row, max_min_value_row, min_max_strategy_col, min_max_value_col = find_max_min_strategies(matching_pennies)\n",
        "\n",
        "print(\"Max-Min Strategy (Row Player):\", max_min_strategy_row)\n",
        "print(\"Min-Max Strategy (Column Player):\", min_max_strategy_col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTaktTuCkK0L",
        "outputId": "fab5fe6f-eca4-4190-b928-e519e0e2c4d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.5, 0.5]), array([0.5, 0.5]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "game = nash.Game(matching_pennies)\n",
        "game.linear_program()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRNIX7rHs11u",
        "outputId": "e6bd2e72-f3aa-4666-f35b-9f21a3ba699c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Payoff Matrix:\n",
            "[[ -8   7   3  -3  -1]\n",
            " [  2  -6  -6   3  -6]\n",
            " [ -8  -9 -10   4   1]\n",
            " [ -4  -8   9   5   0]\n",
            " [  5   1  -7  -1  -9]]\n"
          ]
        }
      ],
      "source": [
        "def generate_payoff_matrix(n):\n",
        "    ### Generate random integers for the payoff matrix\n",
        "    payoff_matrix = np.random.randint(-10, 10, size=(n, n))\n",
        "\n",
        "    return payoff_matrix\n",
        "n = 5\n",
        "random_payoff_matrix = generate_payoff_matrix(n)\n",
        "\n",
        "print(\"Random Payoff Matrix:\")\n",
        "print(random_payoff_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFPnrKJis_sQ",
        "outputId": "7de09ff9-d664-449d-aeac-4afdc3a98e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max-Min Strategy (Row Player): [0.21 0.   0.   0.53 0.26]\n",
            "Min-Max Strategy (Column Player): [0.37 0.13 0.   0.   0.5 ]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "max_min_strategy_row, max_min_value_row, min_max_strategy_col, min_max_value_col = find_max_min_strategies(random_payoff_matrix)\n",
        "\n",
        "print(\"Max-Min Strategy (Row Player):\", max_min_strategy_row)\n",
        "print(\"Min-Max Strategy (Column Player):\", min_max_strategy_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EtSJ-8NtKmU",
        "outputId": "5b62d8b6-6199-46d3-eed2-adfa10bf78b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.21, 0.  , 0.  , 0.53, 0.26]), array([0.37, 0.13, 0.  , 0.  , 0.5 ]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "game = nash.Game(random_payoff_matrix)\n",
        "game.linear_program()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKYl-oLbVM8g"
      },
      "source": [
        "# **NORMAL FORM GAMES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikQrvH9HQ14x"
      },
      "source": [
        "# **DOUBLE ORACLE ALGORITHM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLEgMQ5aCYJc",
        "outputId": "9e01af7d-5c3d-4a64-b001-fbb8f5ed9844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.08 s ± 283 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "Players 1 optimal policy:  [0.01 0.01 0.02 0.   0.01 0.03 0.   0.   0.   0.   0.01 0.   0.03 0.02\n",
            " 0.   0.   0.   0.   0.01 0.   0.   0.02 0.   0.01 0.   0.   0.   0.\n",
            " 0.   0.03 0.03 0.   0.01 0.   0.02 0.   0.03 0.01 0.01 0.   0.01 0.\n",
            " 0.03 0.   0.   0.03 0.   0.   0.   0.02 0.01 0.05 0.   0.01 0.   0.\n",
            " 0.01 0.01 0.01 0.   0.   0.01 0.07 0.   0.01 0.   0.03 0.   0.03 0.\n",
            " 0.   0.01 0.   0.   0.   0.   0.   0.02 0.   0.05 0.   0.   0.03 0.\n",
            " 0.02 0.02 0.03 0.02 0.   0.04 0.01 0.03 0.   0.02 0.   0.   0.   0.\n",
            " 0.   0.03]\n",
            "Players 2 optimal policy:  [0.   0.   0.   0.01 0.01 0.02 0.02 0.   0.04 0.   0.   0.   0.03 0.\n",
            " 0.05 0.01 0.   0.05 0.01 0.   0.01 0.   0.02 0.   0.   0.02 0.   0.01\n",
            " 0.03 0.   0.02 0.04 0.01 0.04 0.   0.   0.   0.03 0.01 0.   0.02 0.\n",
            " 0.03 0.01 0.   0.   0.04 0.03 0.   0.   0.02 0.02 0.01 0.   0.01 0.\n",
            " 0.02 0.02 0.   0.   0.   0.   0.02 0.02 0.   0.   0.06 0.01 0.   0.\n",
            " 0.02 0.01 0.01 0.03 0.01 0.   0.   0.   0.01 0.   0.02 0.   0.   0.\n",
            " 0.   0.   0.01 0.02 0.   0.   0.   0.01 0.   0.   0.   0.   0.02 0.\n",
            " 0.   0.  ]\n"
          ]
        }
      ],
      "source": [
        "def solve_reduced_matrix(payoff_matrix, R, C):\n",
        "  ### Solve the reduced matrix using linear programming and return the optmal policy for this reduced matrix\n",
        "  q, p = np.zeros(len(R)), np.zeros(len(C))\n",
        "  reduced_matrix = payoff_matrix[R == 1, :][:, C == 1]\n",
        "  game = nash.Game(reduced_matrix)\n",
        "  q_, p_ = game.linear_program()\n",
        "  q[R==1], p[C==1] = q_, p_\n",
        "  return q, p\n",
        "\n",
        "\n",
        "def get_pure_strategy(matrix, q, p):\n",
        "  ### Get the pure strategies\n",
        "  r = np.argmax(np.dot(matrix, p))\n",
        "  c = np.argmax(np.dot(q, - matrix))\n",
        "  return r, c\n",
        "\n",
        "def double_oracle_algorithm(matrix):\n",
        "  ### The double oracle algorithm\n",
        "  R, C = np.zeros(matrix.shape[0]), np.zeros(matrix.shape[1])\n",
        "  R[0], C[0] = 1, 1\n",
        "  history_q , history_p = [], []\n",
        "  while True:\n",
        "    q, p = solve_reduced_matrix(matrix, R, C)\n",
        "    history_p.append(p)\n",
        "    history_q.append(q)\n",
        "    r, c = get_pure_strategy(matrix, q, p)\n",
        "    if R[r] == 1 and C[c] == 1:\n",
        "      return history_q, history_p\n",
        "    else:\n",
        "      R[r], C[c] = 1, 1\n",
        "\n",
        "### Generate random normal form games\n",
        "random_payoff_matrix = generate_payoff_matrix(100)\n",
        "\n",
        "%timeit history_q, history_p = double_oracle_algorithm(random_payoff_matrix)\n",
        "\n",
        "print(\"Players 1 optimal policy: \", history_q[-1])\n",
        "print(\"Players 2 optimal policy: \", history_p[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Jax implementation\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "%timeit\n",
        "def generate_payoff_matrix(size):\n",
        "    return jax.random.uniform(jax.random.PRNGKey(0), shape=(size, size))\n",
        "\n",
        "def solve_reduced_matrix(payoff_matrix, R, C):\n",
        "    q, p = jnp.zeros(len(R)), jnp.zeros(len(C))\n",
        "\n",
        "    reduced_matrix = payoff_matrix[R == 1, :][:, C == 1]\n",
        "    game = nash.Game(reduced_matrix)\n",
        "    q_, p_ = game.linear_program()\n",
        "    q = q.at[R == 1].set(q_)\n",
        "    p = p.at[C == 1].set(p_)\n",
        "    return q, p\n",
        "\n",
        "def get_pure_strategy(matrix, q, p):\n",
        "    r = jnp.argmax(jnp.dot(matrix, p))\n",
        "    c = jnp.argmax(jnp.dot(q, -matrix))\n",
        "    return r, c\n",
        "\n",
        "def double_oracle_algorithm(matrix):\n",
        "    R, C = jnp.zeros(matrix.shape[0]), jnp.zeros(matrix.shape[1])\n",
        "    R = R.at[0].set(1)\n",
        "    C = C.at[0].set(1)\n",
        "    history_q, history_p = [], []\n",
        "\n",
        "    while True:\n",
        "        q, p = solve_reduced_matrix(matrix, R, C)\n",
        "        history_p.append(p)\n",
        "        history_q.append(q)\n",
        "        r, c = get_pure_strategy(matrix, q, p)\n",
        "\n",
        "        if R[r] == 1 and C[c] == 1:\n",
        "            return history_q, history_p\n",
        "        else:\n",
        "            R = R.at[r].set(1)\n",
        "            C = C.at[c].set(1)\n",
        "\n",
        "random_payoff_matrix = generate_payoff_matrix(100)\n",
        "\n",
        "%timeit history_q, history_p = double_oracle_algorithm(random_payoff_matrix)\n",
        "print(\"Players 1 optimal policy: \", history_q[-1])\n",
        "print(\"Players 2 optimal policy: \", history_p[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr22QURjdWFD",
        "outputId": "101f0d4e-dfd6-4953-941a-5ca9cdd34430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.73 s ± 116 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "Players 1 optimal policy:  [0.01 0.01 0.02 0.   0.01 0.03 0.   0.   0.   0.   0.01 0.   0.03 0.02\n",
            " 0.   0.   0.   0.   0.01 0.   0.   0.02 0.   0.01 0.   0.   0.   0.\n",
            " 0.   0.03 0.03 0.   0.01 0.   0.02 0.   0.03 0.01 0.01 0.   0.01 0.\n",
            " 0.03 0.   0.   0.03 0.   0.   0.   0.02 0.01 0.05 0.   0.01 0.   0.\n",
            " 0.01 0.01 0.01 0.   0.   0.01 0.07 0.   0.01 0.   0.03 0.   0.03 0.\n",
            " 0.   0.01 0.   0.   0.   0.   0.   0.02 0.   0.05 0.   0.   0.03 0.\n",
            " 0.02 0.02 0.03 0.02 0.   0.04 0.01 0.03 0.   0.02 0.   0.   0.   0.\n",
            " 0.   0.03]\n",
            "Players 2 optimal policy:  [0.   0.   0.   0.01 0.01 0.02 0.02 0.   0.04 0.   0.   0.   0.03 0.\n",
            " 0.05 0.01 0.   0.05 0.01 0.   0.01 0.   0.02 0.   0.   0.02 0.   0.01\n",
            " 0.03 0.   0.02 0.04 0.01 0.04 0.   0.   0.   0.03 0.01 0.   0.02 0.\n",
            " 0.03 0.01 0.   0.   0.04 0.03 0.   0.   0.02 0.02 0.01 0.   0.01 0.\n",
            " 0.02 0.02 0.   0.   0.   0.   0.02 0.02 0.   0.   0.06 0.01 0.   0.\n",
            " 0.02 0.01 0.01 0.03 0.01 0.   0.   0.   0.01 0.   0.02 0.   0.   0.\n",
            " 0.   0.   0.01 0.02 0.   0.   0.   0.01 0.   0.   0.   0.   0.02 0.\n",
            " 0.   0.  ]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}